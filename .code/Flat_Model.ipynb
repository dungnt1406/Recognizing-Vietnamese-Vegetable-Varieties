{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"1R5CC7ThrxgspcHE6gyK5ezpA15KHfll8","authorship_tag":"ABX9TyNdqKzywxchrMeqBzuNiEl1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"OmQJJJvu3JU3"},"outputs":[],"source":["import tensorflow.keras.layers as tfl\n","from tensorflow.keras import Model, Input, utils, regularizers\n","from tensorflow.keras.applications import MobileNetV3Small\n","from tensorflow import reshape\n","from keras.optimizers import Adam\n","from tensorflow.keras.optimizers.schedules import ExponentialDecay\n","from tensorflow.data import Dataset\n","import h5py\n","import tensorflow as tf\n","import numpy as np\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["def backbone_model(\n","    image_shape = (224, 224 , 3),\n","    category_depth = 9,\n","    trainable = False):\n","\n","    '''\n","    image_shape - the shape of the input images\n","    category_depth - the position of the layer where we using as the input of category\n","    trainable - whether to train the backbone or not\n","    ************************************\n","    return - A model that outputs the encoding for category classification task and grading task\n","    '''\n","\n","    backbone = MobileNetV3Small(\n","    input_shape= image_shape,\n","    include_top= False,\n","    weights= 'imagenet',\n","    input_tensor= None,\n","    dropout_rate= 0.2,\n","    include_preprocessing= True)\n","\n","    backbone.trainable = trainable\n","\n","    last_layer = backbone.get_layer(backbone.layers[-1].name).output\n","\n","    conv_output = backbone.get_layer(f'expanded_conv_{str(category_depth)}/Add').output\n","\n","    return Model(inputs = backbone.input, outputs = [last_layer, conv_output])"],"metadata":{"id":"nkY3SKc74jKM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def flat_model(\n","    image_shape = (224, 224 , 3),\n","    num_class = 4,\n","    L2 = 0\n","):\n","\n","    '''\n","    image_shape - the shape of the input images\n","    num_class - the number ouput nodes or number of classes\n","    L2 - the weight decay coefficient\n","    ************************************\n","    return - A model that outputs the predicted probabilities for each class\n","    '''\n","    #initialize the backbone model\n","    backbone = backbone_model(\n","    image_shape = image_shape,\n","    trainable = False)\n","\n","    backbone.trainable = False\n","\n","    input = Input(shape = image_shape)\n","\n","    [last_layer, _] = backbone(input, training = False)\n","\n","\n","    X = tfl.Flatten()(last_layer)\n","    X = tfl.Dense(200, activation = 'relu', kernel_regularizer= regularizers.l2(L2))(X)\n","    X = tfl.Dropout(0.2)(X)\n","    X = tfl.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(L2))(X)\n","    X = tfl.Dropout(0.2)(X)\n","    outputs = tfl.Dense(num_class, activation = 'softmax', name = 'category')(X)\n","\n","    model = Model(inputs = input, outputs = outputs)\n","\n","    return model"],"metadata":{"id":"LiIDdobk4mdp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#customize accuracy function to validate the ability of predict category and quality independently\n","\n","def category_accuracy(y_true, y_pred):\n","    y_true = tf.argmax(y_true, axis = 1)//3\n","    y_pred = tf.argmax(y_pred, axis = 1)//3\n","    return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred), tf.float32))\n","\n","def grade_accuracy(y_true, y_pred):\n","    y_true = tf.argmax(y_true, axis = 1).numpy()%3\n","    y_pred = tf.argmax(y_pred, axis = 1).numpy()%3\n","    return tf.reduce_mean(tf.cast(tf.equal(y_true, y_pred), tf.float32))"],"metadata":{"id":"s-QzdY7H4nxX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["file_path = '/content/drive/MyDrive/DAP391m_G06_AI1807/Data/TRAIN DATA/flat_15_224x224_21952.h5'\n","# file_path = '/content/drive/MyDrive/DAP391m_G06_AI1807/Data/TRAIN DATA/hierachical_6_3_224x224_30350.h5'\n","\n","with h5py.File(file_path, 'r') as hf:\n","    X = hf['images'][()]\n","    Class = hf['class'][()]\n","print(X.shape)\n","X_shape = X.shape\n","print(Class.shape)\n","num_class = len(set(Class))\n","print(num_class)\n","Labels = np.array(reshape(utils.to_categorical(Class,num_class),(-1,num_class)))\n","\n","print(Labels.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7bbRmy_Q4sZy","executionInfo":{"status":"ok","timestamp":1721408493373,"user_tz":-420,"elapsed":64283,"user":{"displayName":"Ngo Van Tuan Anh (K18 HL)","userId":"07701595409112294048"}},"outputId":"85821458-50dd-4887-f196-a5deba20c13d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(21952, 224, 224, 3)\n","(21952,)\n","12\n","(21952, 12)\n"]}]},{"cell_type":"code","source":["X_train, X_test, Labels_train, Labels_test = train_test_split(\n","    X, Labels, test_size=0.2, random_state=42\n",")\n","del Class\n","del X\n","train_set = Dataset.from_tensor_slices((X_train, Labels_train))\n","train_set = train_set.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n","train_set = train_set.batch(32)\n","\n","test_set = Dataset.from_tensor_slices((X_test, Labels_test))\n","test_set = test_set.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n","test_set = test_set.batch(32)\n","\n","del X_train\n","del Labels_train\n","del Labels_test"],"metadata":{"id":"LVgjrjOg5Cvo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lr_schedule = ExponentialDecay(\n","    2e-4,\n","    decay_steps=2500,\n","    decay_rate=0.7,\n","    staircase=True\n",")\n","train_set = train_set.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n","\n","cardinary_model = flat_model(image_shape=(X_shape[1],X_shape[2],3), num_class=num_class, L2=0.2)\n","cardinary_model.compile(optimizer = Adam(learning_rate=lr_schedule,), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n","cardinary_model.fit(train_set, epochs = 25)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SQOICMS38JuG","executionInfo":{"status":"ok","timestamp":1721408973016,"user_tz":-420,"elapsed":394633,"user":{"displayName":"Ngo Van Tuan Anh (K18 HL)","userId":"07701595409112294048"}},"outputId":"ea611769-e5ee-4032-fbaf-f1312dcc2bea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n","4334752/4334752 [==============================] - 1s 0us/step\n","Epoch 1/25\n","549/549 [==============================] - 21s 22ms/step - loss: 23.1192 - accuracy: 0.7165\n","Epoch 2/25\n","549/549 [==============================] - 11s 20ms/step - loss: 2.6322 - accuracy: 0.8071\n","Epoch 3/25\n","549/549 [==============================] - 12s 22ms/step - loss: 1.5830 - accuracy: 0.8066\n","Epoch 4/25\n","549/549 [==============================] - 12s 22ms/step - loss: 1.5461 - accuracy: 0.7988\n","Epoch 5/25\n","549/549 [==============================] - 11s 21ms/step - loss: 1.4550 - accuracy: 0.8077\n","Epoch 6/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.3180 - accuracy: 0.8250\n","Epoch 7/25\n","549/549 [==============================] - 11s 21ms/step - loss: 1.3203 - accuracy: 0.8295\n","Epoch 8/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.3207 - accuracy: 0.8258\n","Epoch 9/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.2929 - accuracy: 0.8328\n","Epoch 10/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.1306 - accuracy: 0.8521\n","Epoch 11/25\n","549/549 [==============================] - 11s 21ms/step - loss: 1.0911 - accuracy: 0.8586\n","Epoch 12/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.0916 - accuracy: 0.8619\n","Epoch 13/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.0814 - accuracy: 0.8613\n","Epoch 14/25\n","549/549 [==============================] - 11s 20ms/step - loss: 1.0358 - accuracy: 0.8693\n","Epoch 15/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.9127 - accuracy: 0.8892\n","Epoch 16/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.9104 - accuracy: 0.8924\n","Epoch 17/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.9145 - accuracy: 0.8898\n","Epoch 18/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.9063 - accuracy: 0.8908\n","Epoch 19/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.8358 - accuracy: 0.9053\n","Epoch 20/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.7789 - accuracy: 0.9127\n","Epoch 21/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.7781 - accuracy: 0.9146\n","Epoch 22/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.7733 - accuracy: 0.9152\n","Epoch 23/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.7654 - accuracy: 0.9207\n","Epoch 24/25\n","549/549 [==============================] - 11s 19ms/step - loss: 0.6937 - accuracy: 0.9362\n","Epoch 25/25\n","549/549 [==============================] - 11s 20ms/step - loss: 0.6914 - accuracy: 0.9342\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7d3e0ae360e0>"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["all_X = []\n","all_y = []\n","for batch in test_set:\n","    X, y = batch  # Unpack the batch into X (inputs) and y (labels)\n","    # Collect batch of inputs\n","    all_X.append(X.numpy())  # Assuming X is a TensorFlow tensor, convert to NumPy if needed\n","    all_y.append(y.numpy())  # Assuming y is a TensorFlow tensor, convert to NumPy if needed\n","# Concatenate all batches into single arrays or lists\n","all_X = tf.concat(all_X, axis=0)  # Concatenate along batch dimension if X is a tensor\n","all_y = tf.concat(all_y, axis=0)  # Concatenate along batch dimension if y is a tensor"],"metadata":{"id":"3h5tUGFT8mC8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["results = cardinary_model.evaluate(test_set)\n","y_pred = cardinary_model.predict(all_X)\n","print('Category_Accuracy :', category_accuracy(all_y, y_pred).numpy())\n","print('Grade_Accuracy :', grade_accuracy(all_y, y_pred).numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVOTGtWG82Ny","executionInfo":{"status":"ok","timestamp":1721408984108,"user_tz":-420,"elapsed":9827,"user":{"displayName":"Ngo Van Tuan Anh (K18 HL)","userId":"07701595409112294048"}},"outputId":"56f5deec-3737-4665-eacb-7463a8dd09e5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["138/138 [==============================] - 4s 25ms/step - loss: 0.7442 - accuracy: 0.9053\n","138/138 [==============================] - 3s 15ms/step\n","Category_Accuracy : 0.9553632\n","Grade_Accuracy : 0.93236166\n"]}]}]}